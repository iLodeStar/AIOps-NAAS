# vector.toml - Vector v0.49 (Debian)

[api]
enabled = true
address = "0.0.0.0:8686"

# ----------------------
# Sources
# ----------------------
[sources.host_metrics]
type = "host_metrics"
scrape_interval_secs = 10

[sources.syslog_udp]
type = "syslog"
address = "0.0.0.0:1514"
mode = "udp"

[sources.syslog_tcp]
type = "syslog"
address = "0.0.0.0:1516"
mode = "tcp"

[sources.snmp_nats]
type = "nats"
url = "nats://nats:4222"
subject = "telemetry.network.>"
connection_name = "vector-snmp-collector"

[sources.app_logs_nats]
type = "nats"
url = "nats://nats:4222"
subject = "logs.applications"
connection_name = "vector-app-logs"

[sources.file_logs]
type = "file"
include = ["/var/log/sample/*.log"]
read_from = "beginning"

# Windows Event Log support (via file or network source)
[sources.windows_eventlog]
type = "file"
include = ["/var/log/windows/*.json", "/var/log/windows/*.xml"]
read_from = "beginning"

# JSON logs source for structured vendor logs
[sources.json_logs]
type = "file"
include = ["/var/log/json/*.json", "/var/log/structured/*.jsonl"]
read_from = "beginning"

# ----------------------
# Transforms
# ----------------------
[transforms.metrics_for_logs]
type = "metric_to_log"
inputs = ["host_metrics"]

[transforms.format_for_clickhouse]
type = "remap"
inputs = ["metrics_for_logs"]
source = '''
metric_value = if exists(.counter) { .counter.value } else if exists(.gauge) { .gauge.value } else { 0.0 }
metric_name = .name

.timestamp = format_timestamp!(.timestamp, "%Y-%m-%d %H:%M:%S%.3f")
.level = "INFO"
.source = "host_metrics"
.message = "Metric: " + to_string!(metric_name) + " = " + to_string!(metric_value)
.host = to_string!(.host)
.service = "metrics-collector"
.raw_log = encode_json(.)
.labels = if exists(.tags) { .tags } else { {} }

del(.counter)
del(.gauge)
'''

# Enhanced syslog processing with vendor-specific parsing
[transforms.syslog_vendor_parse]
type = "remap"
inputs = ["syslog_udp", "syslog_tcp"]
source = '''
.message = to_string!(.message)
.timestamp = if exists(.timestamp) {
    format_timestamp!(.timestamp, "%Y-%m-%d %H:%M:%S%.3f")
} else {
    format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
}
.level = "INFO"
.source = "syslog"
.host = if exists(.hostname) { .hostname } else { "unknown" }
.service = if exists(.appname) { .appname } else { "system" }
.raw_log = encode_json(.)
.labels = {}

# Initialize vendor fields with defaults
.vendor = ""
.device_type = ""
.cruise_segment = ""
.facility = if exists(.facility) { to_string(.facility) } else { "" }
.severity = "info"
.category = ""
.event_id = ""
.ip_address = "0.0.0.0"
.ingestion_time = format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")

# Extract priority and calculate facility/severity from syslog priority
syslog_priority = if exists(.priority) { .priority } else { null }
if syslog_priority != null && syslog_priority >= 0 && syslog_priority <= 191 {
    facility_code = floor(syslog_priority / 8)
    severity_code = syslog_priority % 8
    
    .facility = if facility_code == 16 { "mail" }
        else if facility_code == 17 { "news" } 
        else if facility_code == 18 { "uucp" }
        else if facility_code == 19 { "cron" }
        else if facility_code == 20 { "auth" }
        else if facility_code == 21 { "syslog" }
        else if facility_code == 22 { "lpr" }
        else if facility_code == 23 { "news" }
        else if facility_code == 0 { "kernel" }
        else if facility_code == 1 { "user" }
        else if facility_code == 2 { "mail" }
        else if facility_code == 3 { "daemon" }
        else if facility_code == 4 { "auth" }
        else if facility_code == 5 { "syslog" }
        else if facility_code == 6 { "lpr" }
        else if facility_code == 7 { "news" }
        else { "local" + to_string(facility_code - 16) }
    
    .severity = if severity_code == 0 { "emergency" }
        else if severity_code == 1 { "alert" }
        else if severity_code == 2 { "critical" }
        else if severity_code == 3 { "error" }
        else if severity_code == 4 { "warning" }
        else if severity_code == 5 { "notice" }
        else if severity_code == 6 { "info" }
        else { "debug" }
}

# Parse vendor-specific message formats
msg = to_string(.message)

# Cisco parsing - %FACILITY-SEVERITY-MNEMONIC: message
cisco_match, err = parse_regex(msg, r'%(?P<facility>[A-Z_]+)-(?P<severity_num>\d)-(?P<mnemonic>[A-Z_]+):\s*(?P<message_text>.*)')
if cisco_match != null {
    .vendor = "cisco"
    .facility = downcase(cisco_match.facility)
    .category = downcase(cisco_match.mnemonic)
    .event_id = cisco_match.mnemonic
    .message = cisco_match.message_text
    
    # Map Cisco severity numbers to standard levels
    .severity = if cisco_match.severity_num == "0" { "emergency" }
        else if cisco_match.severity_num == "1" { "alert" }
        else if cisco_match.severity_num == "2" { "critical" }
        else if cisco_match.severity_num == "3" { "error" }
        else if cisco_match.severity_num == "4" { "warning" }
        else if cisco_match.severity_num == "5" { "notice" }
        else if cisco_match.severity_num == "6" { "info" }
        else { "debug" }
        
    .level = upcase(.severity)
}

# Juniper parsing - facility.severity: message
juniper_match, err = parse_regex(msg, r'(?P<facility>[a-zA-Z_]+)\.(?P<severity>[a-zA-Z]+):\s*(?P<message_text>.*)')
if juniper_match != null && .vendor == "" {
    .vendor = "juniper"
    .facility = downcase(juniper_match.facility)
    .severity = downcase(juniper_match.severity)
    .message = juniper_match.message_text
    .level = upcase(.severity)
}

# Fortinet parsing - structured key=value format
fortinet_match, err = parse_regex(msg, r'devname="(?P<device_name>[^"]*)".*?logid="(?P<event_id>[^"]*)".*?type="(?P<category>[^"]*)".*?level="(?P<severity>[^"]*)".*?msg="(?P<message_text>[^"]*)"')
if fortinet_match != null && .vendor == "" {
    .vendor = "fortinet"
    .event_id = fortinet_match.event_id
    .category = fortinet_match.category
    .severity = if fortinet_match.severity == "information" { "info" } else { fortinet_match.severity }
    .message = fortinet_match.message_text
    .level = upcase(.severity)
}

# Palo Alto parsing - basic detection
if contains(msg, ",TRAFFIC,") || contains(msg, ",THREAT,") && .vendor == "" {
    .vendor = "paloalto"
    .category = "traffic"
    .severity = "info"
    .level = upcase(.severity)
}

# Aruba parsing - FACILITY: SEVERITY: message
aruba_match, err = parse_regex(msg, r'(?P<facility>[A-Z_]+):\s*(?P<severity>[A-Z]+):\s*(?P<message_text>.*)')
if aruba_match != null && .vendor == "" {
    .vendor = "aruba"
    .facility = downcase(aruba_match.facility)
    .severity = downcase(aruba_match.severity)
    .message = aruba_match.message_text
    .level = upcase(.severity)
}

# Generic key=value parsing for other vendors
if .vendor == "" && contains(msg, "=") {
    .vendor = "generic_keyvalue"
    .category = "structured"
}
'''

[transforms.syslog_device_classification]
type = "remap"
inputs = ["syslog_vendor_parse"]
source = '''
# Device type classification based on hostname patterns
hostname = downcase(to_string(.host))

# Cisco device classification
if .vendor == "cisco" {
    if match(hostname, r'(sw-|switch-|-sw|-switch|catalyst)') != null {
        .device_type = "switch"
    } else if match(hostname, r'(rtr-|router-|-rtr|-router|isr|asr)') != null {
        .device_type = "router"
    } else if match(hostname, r'(fw-|firewall-|-fw|asa-|-asa)') != null {
        .device_type = "firewall"
    } else if match(hostname, r'(wlc-|-wlc|wireless|controller)') != null {
        .device_type = "wireless_controller"
    } else if match(hostname, r'(ap-|-ap|accesspoint)') != null {
        .device_type = "access_point"
    } else {
        .device_type = "network_device"
    }
}

# Juniper device classification
if .vendor == "juniper" {
    if match(hostname, r'(ex-|-ex|qfx-|-qfx|switch)') != null {
        .device_type = "switch"
    } else if match(hostname, r'(mx-|-mx|ptx-|-ptx|acx-|-acx|router)') != null {
        .device_type = "router"
    } else if match(hostname, r'(srx-|-srx|firewall)') != null {
        .device_type = "firewall"
    } else {
        .device_type = "network_device"
    }
}

# Fortinet device classification
if .vendor == "fortinet" {
    if match(hostname, r'(fgt-|fortigate-|-fgt|fortinet)') != null {
        .device_type = "firewall"
    } else if match(hostname, r'(fgs-|fortiswitch-|-fgs)') != null {
        .device_type = "switch"
    } else if match(hostname, r'(fap-|fortiap-|-fap)') != null {
        .device_type = "access_point"
    } else {
        .device_type = "firewall"  # Default for Fortinet
    }
}

# Palo Alto - primarily firewalls
if .vendor == "paloalto" {
    .device_type = "firewall"
}

# Aruba device classification
if .vendor == "aruba" {
    if match(hostname, r'(switch|procurve|aruba-|hpe-)') != null {
        .device_type = "switch"
    } else if match(hostname, r'(wlc-|controller|airwave)') != null {
        .device_type = "wireless_controller"
    } else if match(hostname, r'(ap-|-ap|instant)') != null {
        .device_type = "access_point"
    } else {
        .device_type = "switch"  # Default for Aruba
    }
}

# Generic device classification for unknown vendors
if .device_type == "" {
    if match(hostname, r'(sw-|switch-|-sw|-switch)') != null {
        .device_type = "switch"
    } else if match(hostname, r'(rtr-|router-|-rtr|-router|gw-|gateway)') != null {
        .device_type = "router"
    } else if match(hostname, r'(fw-|firewall-|-fw)') != null {
        .device_type = "firewall"
    } else if match(hostname, r'(ap-|-ap|accesspoint)') != null {
        .device_type = "access_point"
    } else if match(hostname, r'(srv-|server-|-srv|host-)') != null {
        .device_type = "server"
    } else if match(hostname, r'(vsat-|modem-|satellite-)') != null {
        .device_type = "vsat_terminal"
    } else {
        .device_type = "unknown"
    }
}

# Cruise segment classification based on hostname/location patterns
if match(hostname, r'(bridge|nav|navigation|helm|wheelhouse)') != null {
    .cruise_segment = "navigation"
} else if match(hostname, r'(engine|motor|propulsion|boiler|generator)') != null {
    .cruise_segment = "propulsion"
} else if match(hostname, r'(guest|cabin|dining|entertainment|pool|spa)') != null {
    .cruise_segment = "guest_services"
} else if match(hostname, r'(safety|security|fire|lifeboat|emergency)') != null {
    .cruise_segment = "safety_security"
} else if match(hostname, r'(comms?|communication|radio|satellite|wifi|internet)') != null {
    .cruise_segment = "communications"
} else if match(hostname, r'(power|hvac|water|waste|electrical|utility)') != null {
    .cruise_segment = "utilities"
} else if match(hostname, r'(crew|galley|laundry|maintenance|storage)') != null {
    .cruise_segment = "crew_areas"
} else if match(hostname, r'(deck|cargo|tender|gangway|mooring)') != null {
    .cruise_segment = "deck_operations"
} else {
    .cruise_segment = "general"
}

# Extract IP address if present in the hostname or message
ip_match, err = parse_regex(to_string(.host), r'(?P<ip>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
if ip_match != null {
    .ip_address = ip_match.ip
}
'''

# For backward compatibility, keep the original transform name but point to enhanced version
[transforms.syslog_for_logs]
type = "remap"
inputs = ["syslog_device_classification"]
source = '''
# Pass-through transform for backward compatibility
# All processing is now done in the vendor parsing transforms above
true
'''

[transforms.file_logs_processed]
type = "remap"
inputs = ["file_logs"]
source = '''
.message = to_string!(.message)
.timestamp = if exists(.timestamp) {
    format_timestamp!(.timestamp, "%Y-%m-%d %H:%M:%S%.3f")
} else {
    format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
}
.level = if exists(.level) { .level } else { "INFO" }
.source = "file"
.host = if exists(.host) { .host } else { "unknown" }
.service = if exists(.service) { .service } else { "file-service" }
.raw_log = encode_json(.)
.labels = if exists(.labels) { .labels } else { {} }

# Initialize vendor fields for file logs
.vendor = ""
.device_type = "server"  # File logs typically from servers
.cruise_segment = "general"
.facility = "local0"
.severity = "info"
.category = ""
.event_id = ""
.ip_address = "0.0.0.0"
.ingestion_time = format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
'''

# Windows Event Log processing
# Simplified Windows Event Log processing
[transforms.windows_eventlog_processed] 
type = "remap"
inputs = ["windows_eventlog"]
source = '''
.timestamp = format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
.message = to_string!(.message)
.level = "INFO"
.source = "windows_eventlog"
.host = "windows-server"
.service = "windows-system"
.raw_log = encode_json(.)
.labels = {}

# Windows-specific vendor fields
.vendor = "microsoft"
.device_type = "server"
.cruise_segment = "general"
.facility = "windows"
.severity = "info"
.category = "system"
.event_id = ""
.ip_address = "0.0.0.0"
.ingestion_time = format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
'''

# Simplified JSON structured logs processing
[transforms.json_logs_processed]
type = "remap"
inputs = ["json_logs"]
source = '''
.timestamp = format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
.message = to_string!(.message)
.level = "INFO"
.source = "json_structured"
.host = "json-host"
.service = "json-service"
.raw_log = encode_json(.)
.labels = {}

# JSON vendor fields  
.vendor = "generic"
.device_type = "server"
.cruise_segment = "general"
.facility = "application"
.severity = "info"
.category = "structured"
.event_id = ""
.ip_address = "0.0.0.0"
.ingestion_time = format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
'''

[transforms.snmp_for_logs]
type = "remap"
inputs = ["snmp_nats"]
source = '''
.timestamp = format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
.level = "INFO"

device_type = if exists(.device_type) { to_string(.device_type) } else { "unknown-type" }
device_id = if exists(.device_id) { to_string(.device_id) } else { "unknown-id" }
metric_name = if exists(.metric_name) { to_string(.metric_name) } else { "unknown-metric" }
value = if exists(.value) { to_string(.value) } else { "null" }

.message = "SNMP: " + device_type + " " + device_id + " - " + metric_name + " = " + value

.source = "snmp"
.host = if exists(.device_ip) { .device_ip } else { "unknown" }
.service = if exists(.device_type) { .device_type } else { "network-device" }
.raw_log = encode_json(.)
.labels = if exists(.labels) { .labels } else { {} }

# Initialize vendor fields for SNMP logs
.vendor = ""
.device_type = device_type
.cruise_segment = "general"
.facility = "snmp"
.severity = "info"
.category = "telemetry"
.event_id = ""
.ip_address = if exists(.device_ip) { .device_ip } else { "0.0.0.0" }
.ingestion_time = format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
'''

[transforms.app_logs_for_logs]
type = "remap"
inputs = ["app_logs_nats"]
source = '''
.message = to_string!(.message)
.timestamp = if exists(.timestamp) {
  format_timestamp!(parse_timestamp!(.timestamp, "%Y-%m-%dT%H:%M:%S%.fZ"), "%Y-%m-%d %H:%M:%S%.3f")
} else {
  format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
}
.level = if exists(.level) { .level } else { "INFO" }
.source = "application"
.host = if exists(.host) { .host } else { "unknown" }
.service = if exists(.service) { .service } else { if exists(.application) { .application } else { "app-service" } }
.raw_log = encode_json(.)
.labels = if exists(.metadata) { .metadata } else { {} }

if exists(.application) { .labels.application = .application }
if exists(.logger_name) { .labels.logger_name = .logger_name }
if exists(.trace_id) { .labels.trace_id = .trace_id }
if exists(.span_id) { .labels.span_id = .span_id }
if exists(.thread) { .labels.thread = .thread }
'''

# ----------------------
# Anomaly detection
# ----------------------
[transforms.anomalous_logs_filter]
type = "filter"
inputs = ["syslog_for_logs", "app_logs_for_logs", "windows_eventlog_processed", "json_logs_processed"]
condition = '''
exists(.severity) && (.severity == "err" || .severity == "crit" || .severity == "alert" || .severity == "emerg" || .severity == "critical" || .severity == "error" || .severity == "emergency") ||
exists(.level) && (.level == "ERROR" || .level == "CRITICAL" || .level == "FATAL") ||
(match(to_string!(.message), r'(?i)(error|critical|fail|timeout|connection.*lost|database.*error|system.*failure|alert|emergency|exception|stack.*trace)') != null)
'''

[transforms.anomalous_logs_for_nats]
type = "remap"
inputs = ["anomalous_logs_filter"]
source = '''
.anomaly_type = "log_pattern"
.anomaly_detected_at = format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
.anomaly_source = "vector_log_filter"

.matched = match(to_string!(.message), r'(TEST-[0-9]{8}-[0-9]{6}-[a-f0-9]+|E2E-[0-9]{8}-[0-9]{6}-[a-f0-9]+)')
.tracking_id = if .matched != null { .matched[0] } else { null }

.anomaly_severity = if exists(.severity) {
  if (.severity == "emerg" || .severity == "alert" || .severity == "crit" || .severity == "emergency" || .severity == "critical") {
    "critical"
  } else if (.severity == "err" || .severity == "error") {
    "high"
  } else if (.severity == "warning") {
    "medium"
  } else {
    "low"
  }
} else if exists(.level) {
  if (.level == "FATAL" || .level == "CRITICAL") {
    "critical"
  } else if (.level == "ERROR") {
    "high"
  } else if (.level == "WARN") {
    "medium"
  } else {
    "low"
  }
} else {
  "medium"
}

# Include vendor context in anomaly events with safe string conversion
vendor_str = if exists(.vendor) { to_string!(.vendor) } else { "" }
device_type_str = if exists(.device_type) { to_string!(.device_type) } else { "" }
cruise_segment_str = if exists(.cruise_segment) { to_string!(.cruise_segment) } else { "" }
facility_str = if exists(.facility) { to_string!(.facility) } else { "" }
category_str = if exists(.category) { to_string!(.category) } else { "" }
event_id_str = if exists(.event_id) { to_string!(.event_id) } else { "" }

.vendor_context = {
  "vendor": vendor_str,
  "device_type": device_type_str,
  "cruise_segment": cruise_segment_str,
  "facility": facility_str,
  "category": category_str,
  "event_id": event_id_str
}
'''

# ----------------------
# Observability & Metrics
# ----------------------
[transforms.vendor_metrics]
type = "log_to_metric"
inputs = ["syslog_device_classification", "windows_eventlog_processed", "json_logs_processed"]

# Track log ingestion rate per vendor
[[transforms.vendor_metrics.metrics]]
type = "counter"
field = "vendor"
name = "vector_vendor_logs_total"
namespace = "aiops"
tags.vendor = "{{vendor}}"
tags.device_type = "{{device_type}}"
tags.cruise_segment = "{{cruise_segment}}"
tags.source = "{{source}}"

# Track parsing errors
[[transforms.vendor_metrics.metrics]]
type = "counter" 
field = "parsing_error"
name = "vector_vendor_parsing_errors_total"
namespace = "aiops"
tags.vendor = "{{vendor}}"
tags.error_type = "{{parsing_error}}"
condition = 'exists(.parsing_error)'

# Track severity distribution 
[[transforms.vendor_metrics.metrics]]
type = "counter"
field = "severity"
name = "vector_vendor_severity_total"
namespace = "aiops"
tags.vendor = "{{vendor}}"
tags.device_type = "{{device_type}}"
tags.severity = "{{severity}}"

# Track ingestion latency (log timestamp vs ingestion time)
[[transforms.vendor_metrics.metrics]]
type = "histogram"
field = "ingestion_latency_ms"
name = "vector_vendor_ingestion_latency_seconds"
namespace = "aiops"
tags.vendor = "{{vendor}}"
tags.device_type = "{{device_type}}"

[transforms.calculate_latency]
type = "remap"
inputs = ["syslog_device_classification", "windows_eventlog_processed", "json_logs_processed"]
source = '''
# Simple latency calculation with error handling
timestamp_str = to_string!(.timestamp)
log_timestamp, err = parse_timestamp(timestamp_str, "%Y-%m-%d %H:%M:%S%.3f")
if err == null {
    current_time = now()
    latency_seconds, err = to_float(current_time - log_timestamp)
    if err == null {
        .ingestion_latency_ms = latency_seconds * 1000.0
    } else {
        .ingestion_latency_ms = 0.0
    }
} else {
    .ingestion_latency_ms = 0.0
}

# Pass through all existing fields
true
'''
# ----------------------
# ----------------------
# Sinks
# ----------------------
[sinks.clickhouse]
type = "clickhouse"
inputs = ["format_for_clickhouse", "syslog_for_logs", "file_logs_processed", "windows_eventlog_processed", "json_logs_processed", "snmp_for_logs", "app_logs_for_logs", "calculate_latency"]
endpoint = "http://clickhouse:8123"
database = "logs"
table = "raw"
compression = "gzip"
skip_unknown_fields = true
batch.max_events = 100
batch.timeout_secs = 5

[sinks.clickhouse.auth]
strategy = "basic"
user = "${CLICKHOUSE_USER:-default}"
password = "${CLICKHOUSE_PASSWORD:-clickhouse123}"

# Vendor metrics to VictoriaMetrics
[sinks.vendor_metrics_prometheus]
type = "prometheus_exporter"
inputs = ["vendor_metrics"]
address = "0.0.0.0:8687"
default_namespace = "aiops"

[sinks.anomalous_logs_nats]
type = "nats"
inputs = ["anomalous_logs_for_nats"]
url = "nats://nats:4222"
subject = "logs.anomalous"
[sinks.anomalous_logs_nats.encoding]
codec = "json"

# ----------------------
# Debug sinks
# ----------------------
[sinks.syslog_debug]
type = "console"
inputs = ["syslog_for_logs"]
[sinks.syslog_debug.encoding]
codec = "json"

[sinks.vendor_parsing_debug]
type = "console"
inputs = ["syslog_vendor_parse"]
[sinks.vendor_parsing_debug.encoding]
codec = "json"

[sinks.device_classification_debug]
type = "console"
inputs = ["syslog_device_classification"]
[sinks.device_classification_debug.encoding]
codec = "json"

[sinks.file_debug]
type = "console"
inputs = ["file_logs_processed"]
[sinks.file_debug.encoding]
codec = "json"

[sinks.windows_debug]
type = "console"
inputs = ["windows_eventlog_processed"]
[sinks.windows_debug.encoding]
codec = "json"

[sinks.json_debug]
type = "console"
inputs = ["json_logs_processed"]
[sinks.json_debug.encoding]
codec = "json"

[sinks.snmp_debug]
type = "console"
inputs = ["snmp_for_logs"]
[sinks.snmp_debug.encoding]
codec = "json"

[sinks.transform_debug]
type = "console"
inputs = ["format_for_clickhouse"]
[sinks.transform_debug.encoding]
codec = "json"

