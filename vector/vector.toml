# vector.toml - Vector v0.49 (Debian)

[api]
enabled = true
address = "0.0.0.0:8686"

# ----------------------
# Sources
# ----------------------
[sources.host_metrics]
type = "host_metrics"
scrape_interval_secs = 10

[sources.syslog_udp]
type = "syslog"
address = "0.0.0.0:1514"
mode = "udp"

[sources.syslog_tcp]
type = "syslog"
address = "0.0.0.0:1516"
mode = "tcp"

[sources.snmp_nats]
type = "nats"
url = "nats://nats:4222"
subject = "telemetry.network.>"
connection_name = "vector-snmp-collector"

[sources.app_logs_nats]
type = "nats"
url = "nats://nats:4222"
subject = "logs.applications"
connection_name = "vector-app-logs"

[sources.file_logs]
type = "file"
include = ["/var/log/sample/*.log"]
read_from = "beginning"

# ----------------------
# Transforms
# ----------------------
[transforms.metrics_for_logs]
type = "metric_to_log"
inputs = ["host_metrics"]

[transforms.format_for_clickhouse]
type = "remap"
inputs = ["metrics_for_logs"]
source = '''
metric_value = if exists(.counter) { .counter.value } else if exists(.gauge) { .gauge.value } else { 0.0 }
metric_name = .name

.timestamp = format_timestamp!(.timestamp, "%Y-%m-%d %H:%M:%S%.3f")
.level = "INFO"
.source = "host_metrics"
.message = "Metric: " + to_string!(metric_name) + " = " + to_string!(metric_value)
.host = to_string!(.host)
.service = "metrics-collector"
.raw_log = encode_json(.)
.labels = if exists(.tags) { .tags } else { {} }

del(.counter)
del(.gauge)
'''

[transforms.syslog_for_logs]
type = "remap"
inputs = ["syslog_udp", "syslog_tcp"]
source = '''
.message = to_string!(.message)
.timestamp = if exists(.timestamp) {
    format_timestamp!(.timestamp, "%Y-%m-%d %H:%M:%S%.3f")
} else {
    format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
}
.level = "INFO"
.source = "syslog"
.host = if exists(.hostname) { .hostname } else { "unknown" }
.service = if exists(.appname) { .appname } else { "system" }
.raw_log = encode_json(.)
.labels = {}
'''

[transforms.file_logs_processed]
type = "remap"
inputs = ["file_logs"]
source = '''
.message = to_string!(.message)
.timestamp = if exists(.timestamp) {
    format_timestamp!(.timestamp, "%Y-%m-%d %H:%M:%S%.3f")
} else {
    format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
}
.level = if exists(.level) { .level } else { "INFO" }
.source = "file"
.host = if exists(.host) { .host } else { "unknown" }
.service = if exists(.service) { .service } else { "file-service" }
.raw_log = encode_json(.)
.labels = if exists(.labels) { .labels } else { {} }
'''

[transforms.snmp_for_logs]
type = "remap"
inputs = ["snmp_nats"]
source = '''
.timestamp = format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
.level = "INFO"

device_type, err = if exists(.device_type) { to_string(.device_type) } else { "unknown-type" }
device_id, err = if exists(.device_id) { to_string(.device_id) } else { "unknown-id" }
metric_name, err = if exists(.metric_name) { to_string(.metric_name) } else { "unknown-metric" }
value, err = if exists(.value) { to_string(.value) } else { "null" }

.message = "SNMP: " + device_type + " " + device_id + " - " + metric_name + " = " + value

.source = "snmp"
.host = if exists(.device_ip) { .device_ip } else { "unknown" }
.service = if exists(.device_type) { .device_type } else { "network-device" }
.raw_log = encode_json(.)
.labels = if exists(.labels) { .labels } else { {} }
'''

[transforms.app_logs_for_logs]
type = "remap"
inputs = ["app_logs_nats"]
source = '''
.message = to_string!(.message)
.timestamp = if exists(.timestamp) {
  format_timestamp!(parse_timestamp!(.timestamp, "%Y-%m-%dT%H:%M:%S%.fZ"), "%Y-%m-%d %H:%M:%S%.3f")
} else {
  format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
}
.level = if exists(.level) { .level } else { "INFO" }
.source = "application"
.host = if exists(.host) { .host } else { "unknown" }
.service = if exists(.service) { .service } else { if exists(.application) { .application } else { "app-service" } }
.raw_log = encode_json(.)
.labels = if exists(.metadata) { .metadata } else { {} }

if exists(.application) { .labels.application = .application }
if exists(.logger_name) { .labels.logger_name = .logger_name }
if exists(.trace_id) { .labels.trace_id = .trace_id }
if exists(.span_id) { .labels.span_id = .span_id }
if exists(.thread) { .labels.thread = .thread }
'''

# ----------------------
# V3: Add tracking_id to all logs
# ----------------------
[transforms.add_tracking_id]
type = "remap"
inputs = ["syslog_for_logs"]
source = '''
  .tracking_id = uuid_v4()
  .ingestion_timestamp = now()
'''

# ----------------------
# Anomaly detection
# ----------------------
[transforms.anomalous_logs_filter]
type = "filter"
inputs = ["add_tracking_id", "app_logs_for_logs"]
condition = '''
exists(.severity) && (.severity == "err" || .severity == "crit" || .severity == "alert" || .severity == "emerg") ||
exists(.level) && (.level == "ERROR" || .level == "CRITICAL" || .level == "FATAL") ||
(match(to_string!(.message), r'(?i)(error|critical|fail|timeout|connection.*lost|database.*error|system.*failure|alert|emergency|exception|stack.*trace)') != null)
'''

[transforms.anomalous_logs_for_nats]
type = "remap"
inputs = ["anomalous_logs_filter"]
source = '''
.anomaly_type = "log_pattern"
.anomaly_detected_at = format_timestamp!(now(), "%Y-%m-%d %H:%M:%S%.3f")
.anomaly_source = "vector_log_filter"

.matched = match(to_string!(.message), r'(TEST-[0-9]{8}-[0-9]{6}-[a-f0-9]+|E2E-[0-9]{8}-[0-9]{6}-[a-f0-9]+)')
.tracking_id = if .matched != null { .matched[0] } else { null }

.anomaly_severity = if exists(.severity) {
  if (.severity == "emerg" || .severity == "alert" || .severity == "crit") {
    "critical"
  } else if .severity == "err" {
    "high"
  } else if .severity == "warning" {
    "medium"
  } else {
    "low"
  }
} else if exists(.level) {
  if (.level == "FATAL" || .level == "CRITICAL") {
    "critical"
  } else if (.level == "ERROR") {
    "high"
  } else if (.level == "WARN") {
    "medium"
  } else {
    "low"
  }
} else {
  "medium"
}
'''

# ----------------------
# Sinks
# ----------------------
[sinks.clickhouse]
type = "clickhouse"
inputs = ["format_for_clickhouse", "add_tracking_id", "file_logs_processed", "snmp_for_logs", "app_logs_for_logs"]
endpoint = "http://clickhouse:8123"
database = "logs"
table = "raw"
compression = "gzip"
skip_unknown_fields = true
batch.max_events = 100
batch.timeout_secs = 5

[sinks.clickhouse.auth]
strategy = "basic"
user = "${CLICKHOUSE_USER:-default}"
password = "${CLICKHOUSE_PASSWORD:-clickhouse123}"

[sinks.anomalous_logs_nats]
type = "nats"
inputs = ["anomalous_logs_for_nats"]
url = "nats://nats:4222"
subject = "logs.anomalous"
[sinks.anomalous_logs_nats.encoding]
codec = "json"

# ----------------------
# Debug sinks
# ----------------------
[sinks.syslog_debug]
type = "console"
inputs = ["add_tracking_id"]
[sinks.syslog_debug.encoding]
codec = "json"

[sinks.file_debug]
type = "console"
inputs = ["file_logs_processed"]
[sinks.file_debug.encoding]
codec = "json"

[sinks.snmp_debug]
type = "console"
inputs = ["snmp_for_logs"]
[sinks.snmp_debug.encoding]
codec = "json"

[sinks.transform_debug]
type = "console"
inputs = ["format_for_clickhouse"]
[sinks.transform_debug.encoding]
codec = "json"

