# Benthos configuration for AIOps NAAS v0.4 Enhanced Cross-Source Correlation
# This configuration implements comprehensive rule-based correlation across logs, metrics, SNMP data, and applications
# FIXED VERSION - Addresses null handling and cache key issues

http:
  enabled: true
  address: "0.0.0.0:4195"
  debug_endpoints: true

# Input: Consume fully enriched and processed anomaly events for final correlation
input:
  nats:
    urls: ["nats://nats:4222"]
    subject: "anomaly.detected.enriched.final"
    queue: "benthos_correlation"

# Pipeline for comprehensive event processing and cross-source correlation
pipeline:
  processors:
    # CRITICAL FIX: No longer needed - filter handled upstream in enrichment pipeline
    # All events reaching this stage are already processed and validated
    
    # Input validation and standardization - events are already enriched
    - mapping: |
        # Log enriched input for debugging purposes
        root.debug_input = {
          "raw_content": content(),
          "content_type": content().type(),
          "timestamp": now(),
          "metadata": meta(),
          "pipeline_stage": "benthos_correlation_input"
        }
        
        # Events are already structured and enriched, just validate required fields
        if content().type() == "string" {
          root = content().parse_json()
        } else if content().type() == "object" {
          root = this
        } else {
          # Fallback for unexpected format
          root = {
            "message": content().string(),
            "level": "ERROR", 
            "timestamp": now(),
            "source": "benthos_correlation_fallback",
            "ship_id": "unknown-ship",
            "error": "unexpected_input_format"
          }
        }

    # Enhanced correlation processing for enriched anomaly events
    - mapping: |
        # Generate correlation ID if missing
        root.correlation_id = if this.correlation_id != null && this.correlation_id != "" { 
          this.correlation_id 
        } else { 
          uuid_v4() 
        }
        root.final_processing_timestamp = now()

    # Preserve all enrichment data from previous stages
    - mapping: |
        # Ensure all enriched fields are preserved
        root.ship_id = if this.ship_id != null && this.ship_id != "" { this.ship_id } else { "unknown-ship" }
        root.ship_name = if this.ship_name != null && this.ship_name != "" { this.ship_name } else { 
          if root.ship_id == "unknown-ship" {
            "Unknown Ship"
          } else if root.ship_id.contains("-ship") && root.ship_id.length() > 5 {
            root.ship_id.slice(0, root.ship_id.length() - 5).split("-").map_each(word -> word.uppercase()).join(" ")
          } else {
            root.ship_id.capitalize()
          }
        }
        
        # Preserve enrichment context and maritime context
        root.enrichment_context = if this.enrichment_context != null { this.enrichment_context } else { {} }
        root.maritime_context = if this.maritime_context != null { this.maritime_context } else { {} }
        root.operational_status = if this.operational_status != null { this.operational_status } else { "normal" }
        root.ai_enrichment = if this.ai_enrichment != null { this.ai_enrichment } else { {} }
        
        # Preserve all tracking information for traceability
        root.tracking_id = this.tracking_id
        root.log_message = this.log_message
        
        # Core fields from enriched anomaly
        root.metric_name = if this.metric_name != null { this.metric_name } else { "unknown_metric" }
        root.metric_value = if this.metric_value != null { this.metric_value } else { 0.0 }
        root.anomaly_score = if this.anomaly_score != null { this.anomaly_score } else { 0.5 }
        root.severity = if this.severity != null { this.severity } else { "medium" }
        root.device_id = if this.device_id != null { this.device_id } else { "unknown-device" }
        root.service = if this.service != null { this.service } else { "unknown_service" }
        root.host = if this.host != null { this.host } else { "unknown" }
        
        # Set event source as enriched (all events are now enriched)
        root.event_source = "enriched_anomaly"
        root.is_enriched = true
        root.pipeline_stage = "benthos_correlation_processing"

    # Store enriched anomaly events in correlation cache
    - cache:
        resource: "correlation_cache"  
        operator: "set"
        key: "${! json(\"ship_id\") + \"_enriched_anomaly_\" + json(\"metric_name\") }"
        value: "${! content() }"
        ttl: "600s"  # 10 minute correlation window
        
    # Store by time window for temporal correlation
    - cache:
        resource: "temporal_cache"
        operator: "set"
        key: "${! json(\"ship_id\") + \"_\" + (timestamp_unix() / 300 | floor).string() }"
        value: "${! content() }"
        ttl: "900s"  # 15 minute temporal correlation window

    # Enhanced correlation logic for enriched events
    - switch:
      - check: json("metric_name") == "cpu_usage" || json("metric_name") == "memory_usage"
        processors:
          # Look for related system metrics
          - try:
            - cache:
                resource: "correlation_cache"
                operator: "get"  
                key: "${! if json(\"metric_name\") == \"cpu_usage\" { json(\"ship_id\") + \"_enriched_anomaly_memory_usage\" } else { json(\"ship_id\") + \"_enriched_anomaly_cpu_usage\" } }"
      
      - check: json("enrichment_context").anomaly_enriched == true
        processors:
          # Look for related enriched anomalies from same ship
          - try:
            - cache:
                resource: "correlation_cache"
                operator: "get"
                key: "${! json(\"ship_id\") + \"_enriched_anomaly_\" + if json(\"metric_name\") != \"log_anomaly\" { \"log_anomaly\" } else { \"cpu_usage\" } }"
                
      - check: json("operational_status") != "normal" 
        processors:
          # Look for related anomalies during operational issues
          - try:
            - cache:
                resource: "temporal_cache"
                operator: "get"
                key: "${! json(\"ship_id\") + \"_\" + (timestamp_unix() / 300 | floor).string() }"

    # Create comprehensive correlated incidents with safe null handling
    - mapping: |
        # Initialize incident classification
        root.incident_type = "single_anomaly"
        
        # Parse related event from cache (if available)
        let related = if meta("cache_result") != null && meta("cache_result").type() == "string" {
          meta("cache_result").parse_json() 
        } else {
          null
        }
        
        # Enhanced incident classification logic
        if this.is_enriched && this.operational_status != "normal" {
          # Enhanced operational incidents
          root.incident_type = if this.operational_status == "weather_impacted" {
            "weather_degradation"
          } else if this.operational_status == "system_overloaded" {
            "system_overload"
          } else if this.operational_status == "degraded_comms" {
            "communication_issues"
          } else {
            "operational_anomaly"
          }
          
        } else if this.event_source == "application_logs" && related != null && related.event_source == "basic_metrics" {
          # Application errors correlated with system metrics
          root.incident_type = if related.metric_name != null && (related.metric_name.contains("cpu") || related.metric_name.contains("memory")) {
            "application_system_correlation"
          } else {
            "application_infrastructure_issue"
          }
          
        } else if this.event_source == "basic_metrics" && related != null && related.event_source == "application_logs" {
          # System metrics correlated with application errors
          root.incident_type = "system_application_correlation"
          
        } else if related != null && 
          ((this.metric_name == "cpu_usage" && related.metric_name == "memory_usage") ||
           (this.metric_name == "memory_usage" && related.metric_name == "cpu_usage")) {
          # Traditional CPU/memory correlation
          root.incident_type = "resource_pressure"
          
        } else if this.is_enriched && this.enrichment_context != {} {
          # Multi-source correlation for enriched data
          root.incident_type = "enriched_anomaly"
        }
        
        # Build event list for correlation
        let all_events = [this]
        if related != null {
          all_events = all_events.append(related)
        }
        root.correlated_events = all_events
        
        # Calculate severity priority with comprehensive null safety
        let severity_map = {
          "critical": 4,
          "high": 3,
          "medium": 2,
          "warning": 2,
          "info": 1,
          "debug": 1
        }
        
        # CRITICAL FIX: Ensure severity values are never null with explicit defaults and ultra-safe .get() calls
        let current_severity_raw = if this.severity != null && this.severity != "" && this.severity.type() == "string" { this.severity.lowercase() } else { "info" }
        let current_severity = if current_severity_raw != null && current_severity_raw.type() == "string" { current_severity_raw } else { "info" }
        let severity_priority = if current_severity == "critical" {
          4
        } else if current_severity == "high" {
          3  
        } else if current_severity == "medium" || current_severity == "warning" {
          2
        } else if current_severity == "info" || current_severity == "debug" {
          1
        } else {
          1  # fallback for any unexpected values
        }
        
        let related_severity_raw = if related != null && related.severity != null && related.severity != "" && related.severity.type() == "string" { related.severity.lowercase() } else { "info" }
        let related_severity = if related_severity_raw != null && related_severity_raw.type() == "string" { related_severity_raw } else { "info" }
        let related_priority = if related_severity == "critical" {
          4
        } else if related_severity == "high" {
          3
        } else if related_severity == "medium" || related_severity == "warning" {
          2
        } else if related_severity == "info" || related_severity == "debug" {
          1
        } else {
          if related != null { 1 } else { 0 }
        }
        
        # CRITICAL FIX: Calculate maximum priority safely with explicit null protection
        let max_priority = if severity_priority != null && related_priority != null {
          if severity_priority >= related_priority { severity_priority } else { related_priority }
        } else if severity_priority != null {
          severity_priority
        } else if related_priority != null {
          related_priority
        } else {
          1  # Ultimate fallback
        }
        
        # Set incident severity based on max priority
        root.incident_severity = if max_priority == 4 {
          "critical"
        } else if max_priority == 3 {
          "high"
        } else if max_priority == 2 {
          "medium"
        } else {
          "low"
        }
        
        # Calculate correlation confidence
        root.correlation_confidence = if all_events.length() > 1 {
          0.85  # High confidence with correlated events
        } else if this.is_enriched {
          0.75  # Medium confidence for enriched single events
        } else {
          0.60  # Lower confidence for single basic events
        }
        
        # Add debug information with guaranteed non-null values
        root.debug_priorities = {
          "severity_priority": if severity_priority != null { severity_priority } else { 1 },
          "related_priority": if related_priority != null { related_priority } else { 0 },
          "severity_value": if current_severity != null { current_severity } else { "info" },
          "related_exists": related != null,
          "max_priority": if max_priority != null { max_priority } else { 1 },
          "event_count": all_events.length(),
          "original_severity": if this.severity != null { this.severity } else { "null" },
          "related_severity": if related != null && related.severity != null { related.severity } else { "null" }
        }
        
        # Ensure all required fields are never null
        root.ship_id = if this.ship_id != null && this.ship_id != "" { this.ship_id } else { "unknown-ship" }
        root.incident_type = if this.incident_type != null && this.incident_type != "" { this.incident_type } else { "single_anomaly" }

    # CRITICAL FIX: Enhanced suppression check - prevent duplicate incidents with multiple keys
    - try:
        - cache:
            resource: "suppression_cache"
            operator: "get"
            # More granular suppression key including metric_name and service
            key: "${! if json(\"incident_type\") != null { json(\"incident_type\") } else { \"unknown_incident\" } + \"_\" + if json(\"ship_id\") != null { json(\"ship_id\") } else { \"unknown-ship\" } + \"_\" + if json(\"metric_name\") != null { json(\"metric_name\") } else { \"unknown\" } + \"_\" + if json(\"service\") != null { json(\"service\") } else { \"unknown\" } }"

    # CRITICAL FIX: Additional suppression for tracking_id-based deduplication
    - try:
        - cache:
            resource: "tracking_suppression_cache"
            operator: "get"
            key: "${! if json(\"tracking_id\") != null && json(\"tracking_id\") != \"\" { json(\"tracking_id\") } else { if json(\"ship_id\") != null { json(\"ship_id\") } else { \"unknown-ship\" } + \"_\" + if json(\"metric_name\") != null { json(\"metric_name\") } else { \"unknown\" } + \"_\" + (json(\"processing_timestamp\") / 60 | floor).string() } }"

    # Only process if not suppressed by either check
    - switch:
      - check: (meta("cache_result") == null || meta("cache_result") == "") && (meta("tracking_suppression_cache") == null || meta("tracking_suppression_cache") == "")
        processors:
          # CRITICAL FIX: More granular suppression with longer TTL for similar incidents
          - cache:
              resource: "suppression_cache"
              operator: "set" 
              key: "${! if json(\"incident_type\") != null { json(\"incident_type\") } else { \"unknown_incident\" } + \"_\" + if json(\"ship_id\") != null { json(\"ship_id\") } else { \"unknown-ship\" } + \"_\" + if json(\"metric_name\") != null { json(\"metric_name\") } else { \"unknown\" } + \"_\" + if json(\"service\") != null { json(\"service\") } else { \"unknown\" } }"
              value: "${! json(\"incident_id\") }"  # Store the incident ID for reference
              ttl: "900s"  # Suppress for 15 minutes (longer for better deduplication)
              
          # CRITICAL FIX: Tracking-based suppression
          - cache:
              resource: "tracking_suppression_cache"
              operator: "set"
              key: "${! if json(\"tracking_id\") != null && json(\"tracking_id\") != \"\" { json(\"tracking_id\") } else { if json(\"ship_id\") != null { json(\"ship_id\") } else { \"unknown-ship\" } + \"_\" + if json(\"metric_name\") != null { json(\"metric_name\") } else { \"unknown\" } + \"_\" + (json(\"processing_timestamp\") / 60 | floor).string() } }"
              value: "${! json(\"incident_id\") }"
              ttl: "1800s"  # Suppress for 30 minutes for tracking-based deduplication
              
          # Create final incident event with complete metadata
          - mapping: |
              # Core incident fields
              root.event_type = "incident"
              root.incident_id = uuid_v4()
              root.created_at = now()
              root.updated_at = now()
              root.status = "open"
              root.acknowledged = false
              
              # CRITICAL FIX: Ensure all required fields are populated from processed data
              root.incident_type = if this.incident_type != null && this.incident_type != "" { this.incident_type } else { "single_anomaly" }
              root.incident_severity = if this.incident_severity != null && this.incident_severity != "" { this.incident_severity } else { "medium" }
              root.ship_id = if this.ship_id != null && this.ship_id != "" { this.ship_id } else { "unknown-ship" }
              root.service = if this.service != null && this.service != "" { this.service } else { "unknown_service" }
              root.metric_name = if this.metric_name != null && this.metric_name != "" { this.metric_name } else { "unknown_metric" }
              root.metric_value = if this.metric_value != null { this.metric_value } else { 0.0 }
              root.anomaly_score = if this.anomaly_score != null { this.anomaly_score } else { 0.5 }
              root.device_id = if this.device_id != null && this.device_id != "" { this.device_id } else { "unknown-device" }
              root.correlation_id = if this.correlation_id != null && this.correlation_id != "" { this.correlation_id } else { uuid_v4() }
              
              # CRITICAL FIX: Include tracking information for traceability
              root.tracking_id = if this.tracking_id != null && this.tracking_id != "" { this.tracking_id } else { null }
              
              # CRITICAL FIX: Enhanced timeline with more context
              root.timeline = [
                {
                  "timestamp": now(),
                  "event": "incident_created",
                  "description": "Incident created by anomaly correlation - " + root.incident_type + " on " + root.ship_id,
                  "source": "benthos_correlation",
                  "metadata": {
                    "anomaly_score": root.anomaly_score,
                    "metric_name": root.metric_name,
                    "metric_value": root.metric_value,
                    "tracking_id": root.tracking_id,
                    "correlation_confidence": if this.correlation_confidence != null { this.correlation_confidence } else { 0.6 }
                  }
                }
              ]
              
              # CRITICAL FIX: Enhanced metadata including all source data
              root.metadata = {
                "correlation_confidence": if this.correlation_confidence != null { this.correlation_confidence } else { 0.6 },
                "event_source": if this.event_source != null { this.event_source } else { "unknown" },
                "host": if this.host != null { this.host } else { "unknown" },
                "original_timestamp": if this.timestamp != null { this.timestamp } else { now() },
                "processing_metadata": if this.input_metadata != null { this.input_metadata } else { {} },
                "correlated_events_count": if this.correlated_events != null { this.correlated_events.length() } else { 1 },
                "ship_id_source": if this.ship_id_source != null { this.ship_id_source } else { "unknown" },
                "registry_metadata": if this.registry_metadata != null { this.registry_metadata } else { {} }
              }
              
              # Enhanced runbook suggestions based on incident type and context
              root.suggested_runbooks = if this.incident_type == "resource_pressure" {
                ["investigate_high_resource_usage", "scale_resources", "check_system_limits"]
              } else if this.incident_type == "weather_degradation" {
                ["weather_response_protocol", "switch_backup_comm", "adjust_satellite_parameters"]
              } else if this.incident_type == "communication_issues" {
                ["comm_system_diagnostics", "antenna_alignment_check", "backup_communication"]
              } else if this.incident_type == "system_overload" {
                ["load_balancing", "process_optimization", "resource_scaling"]
              } else if this.incident_type == "application_system_correlation" {
                ["investigate_app_system_correlation", "check_resource_limits", "review_application_logs"]
              } else if this.metric_name == "cpu_usage" {
                ["investigate_cpu_usage", "check_cpu_intensive_processes"]  
              } else if this.metric_name == "memory_usage" {
                ["investigate_memory_usage", "check_memory_leaks"]
              } else if this.event_source == "application_logs" {
                ["review_application_logs", "check_application_health", "investigate_error_patterns"]
              } else {
                ["generic_investigation", "check_system_health"]
              }

      # Drop suppressed events
      - processors:
          - mapping: "root = deleted()"

# Output: Send correlated incidents to multiple destinations
output:
  broker:
    pattern: fan_out
    outputs:
      # Send to NATS for incident management
      - nats:
          urls: ["nats://nats:4222"]
          subject: "incidents.created"
          
      # Log to console for debugging  
      - stdout: {}

# Caching resources for correlation and suppression
cache_resources:
  - label: "correlation_cache" 
    memory:
      default_ttl: "600s"
      
  - label: "temporal_cache"
    memory:
      default_ttl: "900s"
      
  - label: "suppression_cache"
    memory:
      default_ttl: "900s"  # Increased TTL for better deduplication
      
  # CRITICAL FIX: New cache for tracking-based suppression
  - label: "tracking_suppression_cache"
    memory:
      default_ttl: "1800s"  # 30 minutes for tracking-based deduplication

# Metrics and monitoring
metrics:
  prometheus: {}
    
logger:
  level: TRACE
  format: json
  add_timestamp: true