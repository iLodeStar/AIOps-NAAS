# Benthos Correlation and Incident Formation Configuration
# Sequential Pipeline Stage: anomaly.detected.enriched.final → benthos-correlation → incidents.created
# Purpose: Apply deduplication, suppression, correlation logic and create incidents using LLM/Ollama
# Responsibility: Final incident creation with comprehensive correlation and AI-driven analysis

http:
  enabled: true
  address: "0.0.0.0:4195"
  debug_endpoints: true

logger:
  level: INFO
  format: json

# Input: ONLY fully enriched and processed anomalies from enhanced anomaly detection
input:
  nats:
    urls: ["nats://nats:4222"]
    subject: "anomaly.detected.enriched.final"
    queue: "correlation_queue"

pipeline:
  processors:
    # Debug logging for final enriched anomalies
    - log:
        level: INFO
        message: "CORRELATION STAGE: Received final enriched anomaly: ${! json() }"
    
    # Validate final enriched anomaly structure
    - mapping: |
        root = this
        root.correlation_stage = "incident_formation"
        root.processing_timestamp = now()
        
        # Ensure required fields for incident creation
        root.incident_id = uuid_v4()
        root.tracking_id = if this.tracking_id != null { this.tracking_id } else { "unknown" }
        root.ship_id = if this.ship_id != null { this.ship_id } else { "unknown-ship" }
        root.final_anomaly_score = if this.final_anomaly_score != null { this.final_anomaly_score } else { this.anomaly_score }

    # Deduplication Logic - Check for similar recent incidents
    - branch:
        request_map: |
          root = {
            "tracking_id": this.tracking_id,
            "ship_id": this.ship_id,
            "error_pattern": if this.log_message != null { 
              this.log_message.replace_all("[0-9]{4}-[0-9]{2}-[0-9]{2}", "DATE").replace_all("[0-9]{2}:[0-9]{2}:[0-9]{2}", "TIME")
            } else { "unknown" },
            "time_window": "300"  # 5 minutes
          }
        processors:
          - try:
              # Check ClickHouse for recent similar incidents
              - http:
                  url: "http://clickhouse:8123/"
                  verb: POST
                  timeout: "10s"
                  headers:
                    Content-Type: "text/plain"
                  body: |
                    SELECT count() FROM logs.incidents 
                    WHERE ship_id = '${! this.ship_id }' 
                    AND error_pattern LIKE '%${! this.error_pattern.split(" ")[0] }%'
                    AND timestamp > now() - INTERVAL 5 MINUTE
              - mapping: |
                  root.duplicate_count = content().string().trim().number()
          - catch:
              - mapping: |
                  root.duplicate_count = 0
        result_map: |
          root.deduplication_info = {
            "similar_incidents_count": this.duplicate_count,
            "is_duplicate": this.duplicate_count > 0,
            "deduplication_timestamp": now()
          }

    # Suppression Logic - Skip incident creation for duplicates or low-priority events
    - switch:
        - check: |
            this.deduplication_info.is_duplicate == true || 
            (this.final_anomaly_score != null && this.final_anomaly_score < 0.3) ||
            (this.enrichment_context != null && this.enrichment_context.operational_priority == "low" && this.final_anomaly_score < 0.5)
          processors:
            - log:
                level: INFO
                message: "SUPPRESSED: Incident suppressed for tracking_id ${! this.tracking_id } - duplicate or low priority"
            - mapping: "root = deleted()"  # Drop the event

    # Correlation Logic - Group related anomalies and add comprehensive context
    - mapping: |
        root = this
        
        # Cross-reference with ship operational data
        root.correlation_context = {
          "correlation_id": uuid_v4(),
          "related_systems": if this.log_message != null {
            if this.log_message.contains("database") { ["database", "storage"] }
            else if this.log_message.contains("network") { ["network", "communication"] }
            else if this.log_message.contains("engine") { ["propulsion", "power"] }
            else if this.log_message.contains("navigation") { ["navigation", "positioning"] }
            else { ["general"] }
          } else { ["unknown"] },
          "severity_correlation": if this.final_anomaly_score > 0.9 { "critical_incident" }
                                 else if this.final_anomaly_score > 0.7 { "major_incident" }
                                 else if this.final_anomaly_score > 0.5 { "minor_incident" }
                                 else { "informational" },
          "operational_impact": if this.enrichment_context != null && this.enrichment_context.maritime_context != null {
            this.enrichment_context.maritime_context.operational_status
          } else { "unknown_impact" }
        }

    # LLM/Ollama Integration for Incident Analysis and Runbook Selection
    - branch:
        request_map: |
          root = {
            "incident_data": this,
            "analysis_request": {
              "suggest_runbooks": true,
              "analyze_root_cause": true,
              "provide_remediation_steps": true,
              "assess_business_impact": true
            }
          }
        processors:
          - try:
              # LLM analysis for incident formation
              - http:
                  url: "http://ollama:11434/api/generate"
                  verb: POST
                  timeout: "15s"
                  headers:
                    Content-Type: "application/json"
                  body: |
                    {
                      "model": "llama2",
                      "prompt": "Analyze this maritime incident and provide comprehensive remediation guidance. Incident data: ${! json() }. Provide specific runbooks, root cause analysis, and immediate actions required.",
                      "stream": false
                    }
              - mapping: |
                  # Process LLM response for incident formation
                  root.llm_incident_analysis = if this.response != null {
                    {
                      "analysis": content().parse_json().response,
                      "timestamp": now(),
                      "model_used": "llama2"
                    }
                  } else {
                    {
                      "analysis": "LLM analysis failed",
                      "timestamp": now(),
                      "model_used": "none"
                    }
                  }
          - catch:
              # Fallback rule-based incident analysis
              - mapping: |
                  root.llm_incident_analysis = {
                    "analysis": "rule_based_fallback",
                    "suggested_runbooks": if content("incident_data").correlation_context.related_systems.contains("database") {
                      ["investigate_database_connectivity", "check_database_locks", "review_database_performance"]
                    } else if content("incident_data").correlation_context.related_systems.contains("network") {
                      ["network_connectivity_check", "satellite_link_diagnostics", "communication_failover"]
                    } else if content("incident_data").correlation_context.related_systems.contains("engine") {
                      ["engine_diagnostics", "power_system_check", "maintenance_schedule_review"]
                    } else {
                      ["general_system_health_check", "log_analysis", "escalate_to_technical_team"]
                    },
                    "immediate_actions": [
                      "acknowledge_incident",
                      "assess_safety_impact", 
                      "notify_operations_team"
                    ],
                    "estimated_resolution_time": if content("incident_data").final_anomaly_score > 0.8 {
                      "immediate_attention_required"
                    } else {
                      "within_24_hours"
                    }
                  }
        result_map: |
          root.ai_incident_guidance = this.llm_incident_analysis

    # Create final incident object with comprehensive metadata
    - mapping: |
        root = {
          "incident_id": this.incident_id,
          "tracking_id": this.tracking_id,
          "timestamp": now(),
          "ship_id": this.ship_id,
          "device_id": if this.device_id != null { this.device_id } else { "unknown" },
          
          # Original anomaly data preservation
          "original_anomaly": this.original_anomaly,
          
          # Enrichment context from Level 1 and Level 2 processing
          "enrichment_context": this.enrichment_context,
          "enhanced_context": this.enhanced_context,
          
          # Correlation and deduplication info
          "correlation_context": this.correlation_context,
          "deduplication_info": this.deduplication_info,
          
          # AI/LLM analysis and guidance
          "ai_incident_guidance": this.ai_incident_guidance,
          
          # Incident classification
          "severity": this.correlation_context.severity_correlation,
          "priority": if this.final_anomaly_score > 0.8 { "P1_critical" }
                     else if this.final_anomaly_score > 0.6 { "P2_high" }
                     else if this.final_anomaly_score > 0.4 { "P3_medium" }
                     else { "P4_low" },
          "category": this.correlation_context.related_systems[0],
          
          # Incident details
          "title": if this.log_message != null {
            "Maritime System Alert: " + this.log_message.split(" ").slice(0, 10).join(" ")
          } else {
            "System Anomaly Detected on " + this.ship_id
          },
          "description": this.ai_incident_guidance.analysis,
          "suggested_runbooks": this.ai_incident_guidance.suggested_runbooks,
          "immediate_actions": this.ai_incident_guidance.immediate_actions,
          
          # Status and assignment
          "status": "open",
          "assigned_team": if this.correlation_context.severity_correlation == "critical_incident" {
            "operations_emergency_team"
          } else {
            "operations_team"
          },
          
          # Metrics
          "final_anomaly_score": this.final_anomaly_score,
          "correlation_confidence": 0.85,
          "business_impact": this.correlation_context.operational_impact
        }

    # Log incident creation
    - log:
        level: INFO
        message: "INCIDENT CREATED: ${! this.incident_id } for tracking_id ${! this.tracking_id } with severity ${! this.severity }"

# Output: Send incidents to incident API service
output:
  nats:
    urls: ["nats://nats:4222"]
    subject: "incidents.created"

# Metrics for monitoring correlation pipeline
metrics:
  prometheus:
    prefix: benthos_correlation
  mapping: |
    root = this
    root.incidents_created = 1
    root.severity = this.severity
    root.correlation_stage = "final"